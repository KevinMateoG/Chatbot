from fastapi import APIRouter, Body, HTTPException, Depends
import os
import logging
import json
from typing import Optional
from dotenv import load_dotenv
from sqlalchemy.orm import Session
from controller.databaseconfig import get_db
from controller import models, schemas, crud
from pydantic import BaseModel, Field
from model.materia import Materia as MateriaLogica
from model.buzon_sugerencias import BuzonSugerencia

# Cargar variables de entorno desde .env
load_dotenv()

router = APIRouter(prefix="/ai", tags=["ai"])
logger = logging.getLogger(__name__)


# Modelos Pydantic para los requests
class AIGenerateRequest(BaseModel):
    prompt: str = Field(..., description="Texto del prompt")
    model: Optional[str] = Field(None, description="Modelo a usar (opcional)")
    max_tokens: int = Field(512, description="M√°ximo de tokens en la respuesta")
    temperature: float = Field(0.7, description="Temperatura (0.0-2.0)")
    identificacion: Optional[str] = Field(None, description="Identificaci√≥n del estudiante para contexto personalizado")
    usar_contexto: bool = Field(True, description="Si usar el contexto del sistema (JSON + BD)")

# Configuraci√≥n de Groq con API Key (ahora desde variable de entorno)
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")

# Modelos disponibles en Groq (ordenados por velocidad/calidad)
AVAILABLE_MODELS = [
    "llama-3.3-70b-versatile",    # M√°s nuevo y potente (recomendado)
    "llama-3.1-70b-versatile",    # Muy bueno, r√°pido
    "mixtral-8x7b-32768",         # Excelente para espa√±ol
    "llama-3.1-8b-instant",       # Ultra r√°pido
]


def _get_groq_client():
    """Obtiene el cliente de Groq configurado con API key."""
    if not GROQ_API_KEY:
        raise HTTPException(
            status_code=500,
            detail="GROQ_API_KEY no configurada. Obt√©n una en https://console.groq.com/ y config√∫rala como variable de entorno."
        )
    
    try:
        from groq import Groq
        return Groq(api_key=GROQ_API_KEY)
    except ImportError:
        raise HTTPException(
            status_code=500,
            detail="Paquete 'groq' no instalado. Ejecuta: pip install groq"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error configurando Groq: {e}")


def _cargar_contexto_json():
    """Carga el archivo opciones.json para usar como contexto."""
    try:
        ruta_opciones = os.path.join(os.path.dirname(__file__), "opciones.json")
        with open(ruta_opciones, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.warning(f"No se pudo cargar opciones.json: {e}")
        return None


def _obtener_contexto_bd(db: Session, identificacion: str = None):
    """Obtiene informaci√≥n completa y real de la base de datos para el contexto de la IA."""
    contexto = []
    
    try:
        # ============ INFORMACI√ìN DEL USUARIO ============
        if identificacion:
            # Buscar primero como estudiante (el id es la identificaci√≥n)
            estudiante = db.query(models.Estudiante).filter(
                models.Estudiante.id == identificacion
            ).first()
            
            if estudiante:
                contexto.append("=" * 50)
                contexto.append("INFORMACI√ìN DEL ESTUDIANTE")
                contexto.append("=" * 50)
                contexto.append(f"Nombre completo: {estudiante.nombre} {estudiante.apellidos}")
                contexto.append(f"Identificaci√≥n: {estudiante.id}")
                contexto.append(f"Tipo de documento: {estudiante.tipo_id}")
                
                # Materias matriculadas con todos los detalles
                materias = db.query(models.EstudianteMateria, models.Materia).join(
                    models.Materia, models.EstudianteMateria.id_materia == models.Materia.id_materia
                ).filter(
                    models.EstudianteMateria.id_estudiante == estudiante.id
                ).all()
                
                if materias:
                    contexto.append(f"\nMATERIAS MATRICULADAS ({len(materias)} materias):")
                    total_creditos = 0
                    for est_mat, mat in materias:
                        contexto.append(f"  ‚Ä¢ {mat.nombre_materia} - {mat.creditos} cr√©ditos")
                        total_creditos += mat.creditos
                    contexto.append(f"\nTotal de cr√©ditos matriculados: {total_creditos}")
                    
                    # MATERIAS PRIORIZADAS POR CR√âDITOS
                    try:
                        materias_priorizadas = MateriaLogica.ordenar_matrias(estudiante.id)
                        if materias_priorizadas:
                            contexto.append("\nüìä MATERIAS PRIORIZADAS POR CR√âDITOS:")
                            contexto.append("(Ordenadas de mayor a menor prioridad seg√∫n cr√©ditos)")
                            posicion = 1
                            for materia_obj, prioridad in materias_priorizadas.items():
                                contexto.append(f"  {posicion}. {materia_obj.nombre_materia} - {materia_obj.creditos} cr√©ditos (Prioridad: {prioridad})")
                                posicion += 1
                    except Exception as e:
                        logger.warning(f"Error al obtener materias priorizadas: {e}")
                        
                contexto.append("")
            
            # Si no es estudiante, buscar como usuario general
            if not estudiante:
                usuario = db.query(models.Usuario).filter(
                    models.Usuario.id == identificacion
                ).first()
                
                if usuario:
                    contexto.append("=" * 50)
                    contexto.append(f"INFORMACI√ìN DEL {usuario.rol.upper()}")
                    contexto.append("=" * 50)
                    contexto.append(f"Nombre completo: {usuario.nombre} {usuario.apellidos}")
                    contexto.append(f"Identificaci√≥n: {usuario.id}")
                    contexto.append(f"Rol: {usuario.rol}")
                    contexto.append(f"Tipo de documento: {usuario.tipo_id}")
                    contexto.append("")
        
        # ============ TODAS LAS MATERIAS DISPONIBLES ============
        todas_materias = db.query(models.Materia).limit(20).all()
        if todas_materias:
            contexto.append("=" * 50)
            contexto.append(f"MATERIAS DISPONIBLES EN LA UNIVERSIDAD ({len(todas_materias)} primeras):")
            contexto.append("=" * 50)
            for mat in todas_materias:
                contexto.append(f"  ‚Ä¢ {mat.nombre_materia} - {mat.creditos} cr√©ditos")
            contexto.append("")
        
        # ============ USUARIOS DEL SISTEMA ============
        usuarios = db.query(models.Usuario).limit(10).all()
        if usuarios:
            contexto.append("=" * 50)
            contexto.append("USUARIOS DEL SISTEMA:")
            contexto.append("=" * 50)
            for user in usuarios:
                contexto.append(f"ÔøΩ {user.nombre} {user.apellidos}")
                contexto.append(f"   Rol: {user.rol}")
                contexto.append(f"   Tipo ID: {user.tipo_id}")
                contexto.append("")
                
    except Exception as e:
        logger.warning(f"Error obteniendo contexto de BD: {e}")
    
    return "\n".join(contexto) if contexto else None


def _construir_prompt_con_contexto(prompt_usuario: str, contexto_json: dict = None, contexto_bd: str = None):
    """Construye un prompt enriquecido con el contexto del sistema."""
    
    partes = [
        "="*70,
        "ASISTENTE VIRTUAL INTELIGENTE - UNIVERSIDAD DE MEDELL√çN",
        "="*70,
        "",
        "Eres un asistente virtual avanzado de la Universidad de Medell√≠n (UdeM).",
        "",
        "TU MISI√ìN:",
        "- Ayudar a estudiantes y profesores con informaci√≥n precisa y personalizada",
        "- Responder preguntas sobre materias, calificaciones, profesores, eventos",
        "- Mostrar materias priorizadas por cr√©ditos cuando lo soliciten",
        "- Guiar en tr√°mites administrativos y procesos acad√©micos",
        "- Ser amigable, profesional y usar un tono conversacional",
        "",
        "CAPACIDADES:",
        "‚úì Acceso COMPLETO a la base de datos de la universidad",
        "‚úì Informaci√≥n en TIEMPO REAL de estudiantes, profesores, materias, noticias",
        "‚úì Puedes llamar al usuario por su NOMBRE si est√° identificado",
        "‚úì Puedes hacer c√°lculos (promedios, cr√©ditos, etc.)",
        "‚úì Puedes ayudar a los usuarios a enviar SUGERENCIAS al buz√≥n",
        "",
        "REGLAS IMPORTANTES:",
        "1. Si el usuario est√° identificado, dir√≠gete a √©l por su NOMBRE",
        "2. Si preguntan por materias/notas, usa la informaci√≥n REAL de la BD",
        "3. Si preguntan por profesores, usa los datos REALES",
        "4. üìä MATERIAS PRIORIZADAS: Cuando te pregunten por materias priorizadas o por orden de cr√©ditos:",
        "   - USA EXCLUSIVAMENTE la secci√≥n 'üìä MATERIAS PRIORIZADAS POR CR√âDITOS'",
        "   - Muestra el listado COMPLETO tal como aparece en el contexto",
        "   - Explica que est√°n ordenadas de MAYOR a MENOR n√∫mero de cr√©ditos",
        "   - Menciona la prioridad (Alta/Media/Baja) de cada materia",
        "5. üìù BUZ√ìN DE SUGERENCIAS: Si el usuario quiere enviar una queja, reclamo, sugerencia o felicitaci√≥n:",
        "   - Explica que puede enviarlo al buz√≥n de sugerencias",
        "   - Los tipos v√°lidos son: Queja, Reclamo, Sugerencia, Felicitaci√≥n",
        "   - Pide el ASUNTO (tema breve)",
        "   - Pide la DESCRIPCI√ìN (detallada)",
        "   - Indica que su mensaje ser√° registrado y revisado por la universidad",
        "   - NO intentes guardar la sugerencia t√∫ mismo, solo gu√≠a al usuario",
        "   - Cuando el USUARIO te diga el tipo de sugerencias y lo que quiere di gracias",
        "6. Si no tienes la info exacta, sugiere contactar a la universidad",
        "7. SIEMPRE responde en espa√±ol de forma clara y concisa",
        "8. Si hay m√∫ltiples opciones, pres√©ntalas en formato de lista numerada",
        "9. Incluye emojis relevantes para hacer la conversaci√≥n m√°s amigable üòä",
        "",
        "‚ö†Ô∏è REGLA CR√çTICA SOBRE ENLACES:",
        "- Cuando una respuesta incluya una URL, DEBES mostrar el enlace COMPLETO",
        "- NO digas 'haz clic aqu√≠' sin el enlace",
        "- Formato correcto: 'Accede aqu√≠: https://ejemplo.com/url-completa'",
        "- Las URLs pueden ser largas, NO LAS ACORTES",
        "- Siempre verifica en las OPCIONES Y SERVICIOS si hay enlaces disponibles",
        "",
    ]
    
    # Agregar contexto de BD si existe
    if contexto_bd:
        partes.append("="*70)
        partes.append("üìä INFORMACI√ìN DE LA BASE DE DATOS (TIEMPO REAL):")
        partes.append("="*70)
        partes.append(contexto_bd)
        partes.append("")
    
    # Agregar contexto del JSON si existe
    if contexto_json:
        partes.append("="*70)
        partes.append("üìã OPCIONES, SERVICIOS Y ENLACES DISPONIBLES:")
        partes.append("="*70)
        
        # Extraer informaci√≥n completa del JSON incluyendo resultados y URLs
        if "opciones" in contexto_json:
            for key, opcion in contexto_json["opciones"].items():
                partes.append(f"\n{key}. {opcion.get('texto', '')}")
                
                # Si tiene sub-opciones
                if "opciones" in opcion:
                    for sub_key, sub_opcion in opcion["opciones"].items():
                        partes.append(f"   {key}.{sub_key}. {sub_opcion.get('texto', '')}")
                        
                        # IMPORTANTE: Incluir el resultado con URLs
                        if "resultado" in sub_opcion:
                            resultado = sub_opcion["resultado"]
                            partes.append(f"      ‚Üí Resultado: {resultado}")
                
                # Si tiene resultado directo (sin sub-opciones)
                elif "resultado" in opcion:
                    partes.append(f"   ‚Üí Resultado: {opcion['resultado']}")
        
        partes.append("")
        partes.append("üîó INSTRUCCIONES SOBRE ENLACES:")
        partes.append("- Cuando respondas con URLs, SIEMPRE muestra el enlace completo")
        partes.append("- Usa el formato: 'Puedes acceder aqu√≠: [URL completa]'")
        partes.append("- NO acortes ni omitas las URLs")
        partes.append("- Si el resultado contiene un enlace, INCL√öYELO en tu respuesta")
        partes.append("")
    
    # Agregar pregunta del usuario
    partes.append("="*70)
    partes.append("üí¨ PREGUNTA DEL USUARIO:")
    partes.append("="*70)
    partes.append(prompt_usuario)
    partes.append("")
    partes.append("="*70)
    partes.append("üìù TU RESPUESTA (clara, precisa y amigable):")
    partes.append("="*70)
    
    return "\n".join(partes)


@router.get("/verificar_identificacion/{identificacion}")
async def verificar_identificacion(identificacion: str, db: Session = Depends(get_db)):
    """Verifica la identificaci√≥n y retorna el nombre del usuario."""
    try:
        # Buscar como estudiante
        estudiante = db.query(models.Estudiante).filter(
            models.Estudiante.id == identificacion
        ).first()
        
        if estudiante:
            return {
                "encontrado": True,
                "tipo": "estudiante",
                "nombre": f"{estudiante.nombre} {estudiante.apellidos}",
                "identificacion": identificacion
            }
        
        # Buscar como usuario general
        usuario = db.query(models.Usuario).filter(
            models.Usuario.id == identificacion
        ).first()
        
        if usuario:
            return {
                "encontrado": True,
                "tipo": usuario.rol,
                "nombre": f"{usuario.nombre} {usuario.apellidos}",
                "identificacion": identificacion
            }
        
        # No encontrado
        return {
            "encontrado": False,
            "mensaje": "Identificaci√≥n no encontrada en el sistema"
        }
        
    except Exception as e:
        logger.error(f"Error verificando identificaci√≥n: {e}")
        raise HTTPException(status_code=500, detail=f"Error al verificar identificaci√≥n: {str(e)}")


@router.post("/generate")
async def generate_ai(
    request: AIGenerateRequest,
    db: Session = Depends(get_db)
):
    """Genera texto usando Groq (LLaMA/Mixtral) con contexto del sistema.
    
    La IA puede usar:
    - Opciones del chatbot (opciones.json)
    - Informaci√≥n del estudiante de la BD (si se proporciona identificaci√≥n)
    - Noticias, grupos estudiantiles, etc.
    
    Ejemplo de uso:
    ```json
    {
        "prompt": "¬øQu√© materias tengo matriculadas?",
        "identificacion": "1234567890",
        "max_tokens": 256
    }
    ```
    """
    if not request.prompt or not request.prompt.strip():
        raise HTTPException(status_code=400, detail="El prompt no puede estar vac√≠o")

    client = _get_groq_client()
    
    # Construir prompt con contexto si est√° habilitado
    prompt_final = request.prompt
    if request.usar_contexto:
        contexto_json = _cargar_contexto_json()
        contexto_bd = _obtener_contexto_bd(db, request.identificacion) if request.identificacion else None
        prompt_final = _construir_prompt_con_contexto(request.prompt, contexto_json, contexto_bd)
        logger.info(f"Prompt con contexto construido (longitud: {len(prompt_final)} caracteres)")
    
    # Determinar qu√© modelo usar
    models_to_try = [request.model] if request.model else AVAILABLE_MODELS
    
    last_error = None
    for model_name in models_to_try:
        try:
            logger.info(f"Intentando generar con modelo: {model_name}")
            
            # Llamar a Groq API (compatible con OpenAI)
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "user", "content": prompt_final}
                ],
                max_tokens=request.max_tokens,
                temperature=request.temperature,
            )
            
            # Extraer respuesta
            text = response.choices[0].message.content
            
            return {
                "text": text,
                "model": model_name,
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens,
                "finish_reason": response.choices[0].finish_reason,
                "contexto_usado": request.usar_contexto
            }
                
        except Exception as e:
            error_msg = str(e)
            logger.warning(f"Fallo con modelo {model_name}: {error_msg}")
            last_error = error_msg
            
            # Si es un error de modelo no encontrado, probar el siguiente
            if "model" in error_msg.lower() and "not found" in error_msg.lower():
                continue
            else:
                # Otros errores (rate limit, auth, etc.) no reintentar
                raise HTTPException(status_code=500, detail=f"Error al generar con {model_name}: {error_msg}")
    
    # Si llegamos aqu√≠, ning√∫n modelo funcion√≥
    raise HTTPException(
        status_code=502,
        detail=f"No se pudo generar contenido con ning√∫n modelo disponible. √öltimo error: {last_error}"
    )


@router.post("/sugerencia")
async def crear_sugerencia(
    sugerencia: schemas.BuzonSugerenciasBase,
    db: Session = Depends(get_db)
):
    """Crea una nueva sugerencia en el buz√≥n.
    
    Tipos de sugerencia v√°lidos:
    - Queja
    - Reclamo
    - Sugerencia
    - Felicitaci√≥n
    
    Ejemplo de uso:
    ```json
    {
        "id_estudiante": "1234567890",
        "tipo_documento": "CC",
        "tipo_sugerencia": "Sugerencia",
        "asunto": "Mejora en la biblioteca",
        "descripcion": "Ser√≠a genial tener m√°s horarios disponibles los fines de semana."
    }
    ```
    """
    try:
        # Validar tipo de sugerencia
        tipos_validos = ["Queja", "Reclamo", "Sugerencia", "Felicitaci√≥n"]
        if sugerencia.tipo_sugerencia not in tipos_validos:
            raise HTTPException(
                status_code=400, 
                detail=f"Tipo de sugerencia no v√°lido. Debe ser uno de: {', '.join(tipos_validos)}"
            )
        
        # Validar que el estudiante exista
        estudiante = db.query(models.Estudiante).filter(
            models.Estudiante.id == sugerencia.id_estudiante
        ).first()
        
        if not estudiante:
            # Buscar como usuario general
            usuario = db.query(models.Usuario).filter(
                models.Usuario.id == sugerencia.id_estudiante
            ).first()
            
            if not usuario:
                raise HTTPException(
                    status_code=404,
                    detail="Identificaci√≥n no encontrada en el sistema"
                )
        
        # Crear la sugerencia usando el schema
        nueva_sugerencia = schemas.BuzonSugerenciasCreate(
            id_estudiante=sugerencia.id_estudiante,
            tipo_documento=sugerencia.tipo_documento,
            tipo_sugerencia=sugerencia.tipo_sugerencia,
            asunto=sugerencia.asunto,
            descripcion=sugerencia.descripcion,
            estado="Pendiente"
        )
        
        # Guardar en la BD
        sugerencia_guardada = crud.crear_sugerencia(db, nueva_sugerencia)
        
        return {
            "success": True,
            "message": f"¬°Gracias! Tu {sugerencia.tipo_sugerencia.lower()} ha sido registrada con √©xito.",
            "id": sugerencia_guardada.id,
            "estado": sugerencia_guardada.estado,
            "created_at": sugerencia_guardada.created_at.isoformat() if hasattr(sugerencia_guardada, 'created_at') else None
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error al crear sugerencia: {e}")
        raise HTTPException(status_code=500, detail=f"Error al procesar la sugerencia: {str(e)}")


@router.get("/models")
async def list_models():
    """Lista los modelos disponibles de Groq."""
    return {
        "models": [
            {
                "name": "llama-3.3-70b-versatile",
                "description": "LLaMA 3.3 70B - M√°s nuevo y potente, excelente para espa√±ol",
                "context_window": 32768
            },
            {
                "name": "llama-3.1-70b-versatile", 
                "description": "LLaMA 3.1 70B - Muy bueno, equilibrio perfecto",
                "context_window": 131072
            },
            {
                "name": "mixtral-8x7b-32768",
                "description": "Mixtral 8x7B - Excelente para espa√±ol y multiling√ºe",
                "context_window": 32768
            },
            {
                "name": "llama-3.1-8b-instant",
                "description": "LLaMA 3.1 8B - Ultra r√°pido para respuestas simples",
                "context_window": 131072
            }
        ],
        "count": 4,
        "provider": "Groq"
    }